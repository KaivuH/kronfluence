{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Vocabulary Mapping:\n",
      "o: 0\n",
      "=: 1\n",
      "R2: 2\n",
      "R3: 3\n",
      "True: 4\n",
      "R1: 5\n",
      "False: 6\n",
      "\n",
      "Rule Definitions:\n",
      "R1: C OR A\n",
      "R2: NOT A AND C\n",
      "R3: NOT C AND B\n",
      "\n",
      "Fact Values:\n",
      "A: True\n",
      "B: True\n",
      "C: False\n",
      "D: False\n",
      "Error evaluating expression: NOT True TrueNFalse False\n",
      "An error occurred: Invalid expression format: NOT True TrueNFalse False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid expression format: NOT True TrueNFalse False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfact\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fetch a training example\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m train_example, train_label \u001b[38;5;241m=\u001b[39m \u001b[43mlogical_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_train_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Example:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_example)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Label:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_label)\n",
      "File \u001b[0;32m~/kronfluencer/wikitext/grokking/grokk_replica/dataset_maker.py:196\u001b[0m, in \u001b[0;36mLogicalInferenceDataset.fetch_train_example\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_train_example\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mint\u001b[39m], \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    195\u001b[0m     idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pairs)\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/kronfluencer/wikitext/grokking/grokk_replica/dataset_maker.py:189\u001b[0m, in \u001b[0;36mLogicalInferenceDataset.fetch_example\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tuple[List[\u001b[38;5;28mint\u001b[39m], \u001b[38;5;28mint\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m    188\u001b[0m     rule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules[idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules)]\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEVAL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     equation \u001b[38;5;241m=\u001b[39m [rule, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEVAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(result)]\n\u001b[1;32m    191\u001b[0m     example, result_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_example(rule, result)\n",
      "File \u001b[0;32m~/kronfluencer/wikitext/grokking/grokk_replica/dataset_maker.py:164\u001b[0m, in \u001b[0;36mLogicalInferenceDataset.fetch_output\u001b[0;34m(self, rule, eval_statement)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError evaluating expression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/kronfluencer/wikitext/grokking/grokk_replica/dataset_maker.py:161\u001b[0m, in \u001b[0;36mLogicalInferenceDataset.fetch_output\u001b[0;34m(self, rule, eval_statement)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28meval\u001b[39m(parts[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28meval\u001b[39m(parts[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid expression format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError evaluating expression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid expression format: NOT True TrueNFalse False"
     ]
    }
   ],
   "source": [
    "from dataset_maker import LogicalInferenceDataset\n",
    "\n",
    "# Define parameters\n",
    "n_facts = 4  # e.g., A, B, C, D\n",
    "m_rules = 3  # e.g., R1, R2, R3\n",
    "frac_train = 0.8\n",
    "\n",
    "try:\n",
    "    # Initialize the dataset\n",
    "    logical_dataset = LogicalInferenceDataset(n_facts, m_rules, frac_train)\n",
    "\n",
    "    # Print Vocabulary\n",
    "    print(\"Vocabulary Mapping:\")\n",
    "    for token, idx in logical_dataset.vocab2idx.items():\n",
    "        print(f\"{token}: {idx}\")\n",
    "\n",
    "    # Print Rule Definitions\n",
    "    print(\"\\nRule Definitions:\")\n",
    "    for rule, definition in logical_dataset.rule_definitions.items():\n",
    "        print(f\"{rule}: {definition}\")\n",
    "\n",
    "    # Print Fact Values\n",
    "    print(\"\\nFact Values:\")\n",
    "    for fact, value in logical_dataset.fact_values.items():\n",
    "        print(f\"{fact}: {value}\")\n",
    "\n",
    "    # Fetch a training example\n",
    "    train_example, train_label = logical_dataset.fetch_train_example()\n",
    "    print(\"\\nTraining Example:\", train_example)\n",
    "    print(\"Training Label:\", train_label)\n",
    "\n",
    "    # Fetch a validation example\n",
    "    val_example, val_label = logical_dataset.fetch_val_example()\n",
    "    print(\"\\nValidation Example:\", val_example)\n",
    "    print(\"Validation Label:\", val_label)\n",
    "\n",
    "    # Print a full example with equation\n",
    "    full_example, equation = logical_dataset.fetch_example(0)\n",
    "    print(\"\\nFull Example:\")\n",
    "    print(\"Encoded:\", full_example)\n",
    "    print(\"Equation:\", equation)\n",
    "\n",
    "    # Test encoding and decoding\n",
    "    test_sequence = ['R1', 'EVAL', 'True']\n",
    "    encoded = logical_dataset.encode(test_sequence)\n",
    "    decoded = logical_dataset.decode(encoded)\n",
    "    print(\"\\nEncoding Test:\")\n",
    "    print(\"Original:\", test_sequence)\n",
    "    print(\"Encoded:\", encoded)\n",
    "    print(\"Decoded:\", decoded)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "influence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
